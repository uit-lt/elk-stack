networks:
  elk:
    driver: bridge

volumes:
  elasticsearch:
    driver: local

services:
  ## ELASTICSEARCH SERVICE
  elasticsearch:
    container_name: "${COMPOSE_PROJECT_NAME}-elasticsearch"
    image: "docker.elastic.co/elasticsearch/elasticsearch:${STACK_VERSION:-8.14.3}"
    environment:
      - node.name=elasticsearch
      - cluster.name=elasticsearch-cluster
      - discovery.type=${ELASTICSEARCH_DISCOVERY_TYPE:-single-node}
      - xpack.security.enabled=${ELASTICSEARCH_XPACK_SECURITY_ENABLED:-false}
      - xpack.security.enrollment.enabled=${ELASTICSEARCH_XPACK_SECURITY_ENROLLMENT_ENABLED:-false}
      - ES_JAVA_OPTS=${ELASTICSEARCH_JAVA_OPTS}
      - bootstrap.memory_lock=true
      - ELASTIC_PASSWORD=${ELASTIC_PASSWORD}
    ports:
      - "${ELASTICSEARCH_HTTP_PORT:-9200}:9200"
      - "${ELASTICSEARCH_TRANSPORT_PORT:-9300}:9300"
    networks:
      - elk
    volumes:
      - elasticsearch:/var/lib/elasticsearch/data
    ulimits:
      memlock:
        soft: -1
        hard: -1
    healthcheck:
      test: [ "CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1" ]
      interval: 30s
      timeout: 10s
      retries: 5

  ## LOGSTASH SERVICE
  logstash:
    build:
      context: logstash
      args:
        STACK_VERSION: ${STACK_VERSION:-8.14.3}
    container_name: "${COMPOSE_PROJECT_NAME}-logstash"
    environment:
      NODE_NAME: "logstash"
      LS_JAVA_OPTS: "${LS_JAVA_OPTS}"
      ELASTIC_USERNAME: "elastic"
      ELASTIC_PASSWORD: "${ELASTIC_PASSWORD}"
      ELASTIC_HOSTS: "http://elasticsearch:9200"
    volumes:
      - ./logstash/logstash.conf:/usr/share/logstash/pipeline/logstash.conf
      - ./logstash/logstash.yml:/usr/share/logstash/config/logstash.yml
      - ./data/employees.csv:/usr/share/logstash/data/employees.csv
      - ./data/2_people_data_2k.csv:/usr/share/logstash/data/2_people_data_2k.csv
      - ./data/2_connections_data_300k.csv:/usr/share/logstash/data/2_connections_data_300k.csv
    ports:
      - "${LOGSTASH_PORT:-5044}:5044"
      - "${LOGSTASH_TCP_PORT:-5000}:5000"
      - "${LOGSTASH_HTTP_PORT:-9600}:9600"
    command: logstash -f /usr/share/logstash/pipeline/logstash.conf
    depends_on:
      - elasticsearch
    networks:
      - elk

  ## KIBANA SERVICE
  kibana:
    image: docker.elastic.co/kibana/kibana:${STACK_VERSION:-8.14.3}
    container_name: "${COMPOSE_PROJECT_NAME}-kibana"
    environment:
      - node.name=kibana
      - cluster.name=elasticsearch-cluster
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - ELASTICSEARCH_USERNAME=kibana_system
      - ELASTICSEARCH_PASSWORD=${KIBANA_PASSWORD}
    ports:
      - "${KIBANA_PORT:-5601}:5601"
    depends_on:
      - elasticsearch
    platform: ${PLATFORM:-linux/amd64}
    healthcheck:
      test: [ "CMD-SHELL", "curl -s -I http://localhost:5601 | grep -q 'HTTP/1.1 302 Found'" ]
      interval: 30s
      timeout: 5s
      retries: 3
    networks:
      - elk

  ## SPARK SERVICE
  spark-master:
    image: ${SPARK_IMAGE:-bitnami/spark:3.5.1}
    container_name: spark-master
    environment:
      - HOME=/tmp
      - SPARK_MODE=master
      - HADOOP_USER_NAME=root
      - SPARK_RPC_AUTHENTICATION_ENABLE=no
      - SPARK_RPC_ENCRYPTION_ENABLE=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLE=no
      - SPARK_SSL_ENABLE=no
    ports:
      - "${SPARK_MASTER_PORT:-7077}:7077"
      - "${SPARK_MASTER_UI_PORT:-8080}:8080"
    volumes:
      - ${PWD}/spark/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ${PWD}/spark/tests:/opt/bitnami/spark/tests
    depends_on:
      - elasticsearch
    networks:
      - elk

  spark-worker:
    image: ${SPARK_IMAGE:-bitnami/spark:3.5.1}
    container_name: spark-worker
    environment:
      - SPARK_MODE=worker
      - SPARK_WORKER_MEMORY=1g
      - SPARK_WORKER_CORES=1
      - HADOOP_USER_NAME=root
      - SPARK_RPC_AUTHENTICATION_ENABLE=no
      - SPARK_RPC_ENCRYPTION_ENABLE=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLE=no
      - SPARK_SSL_ENABLE=no
    depends_on:
      - spark-master
    volumes:
      - ./spark/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ${PWD}/spark/tests:/opt/bitnami/spark/tests
    ports:
      - "${SPARK_WORKER_UI_PORT:-8081}:8081"
    networks:
      - elk

  spark-worker-2:
    image: ${SPARK_IMAGE:-bitnami/spark:3.5.1}
    container_name: spark-worker-2
    environment:
      - SPARK_MODE=worker
      - SPARK_WORKER_MEMORY=1g
      - SPARK_WORKER_CORES=1
      - HADOOP_USER_NAME=root
      - SPARK_RPC_AUTHENTICATION_ENABLE=no
      - SPARK_RPC_ENCRYPTION_ENABLE=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLE=no
      - SPARK_SSL_ENABLE=no
    depends_on:
      - spark-master
    volumes:
      - ./spark/spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
      - ${PWD}/spark/tests:/opt/bitnami/spark/tests
    ports:
      - "${SPARK_WORKER_UI_PORT_2:-8082}:8081"
    networks:
      - elk


  ## JUPYTER SERVICE
  jupyter:
    image: jupyter/pyspark-notebook:latest
    container_name: jupyter
    hostname: jupyter
    ports:
      - "${JUPYTER_PORT:-8888}:8888"
    environment:
      - JUPYTER_TOKEN=${JUPYTER_TOKEN:-spark}
      - SPARK_OPTS=--conf spark.master=spark://spark-master:7077 --conf spark.driver.host=jupyter --conf spark.driver.bindAddress=0.0.0.0
      - PYSPARK_PYTHON=python3
    volumes:
      - ./spark/spark-defaults.conf:/usr/local/spark/conf/spark-defaults.conf
      - ./jupyter:/home/jovyan/work
    depends_on:
      - spark-master
    networks:
      - elk
